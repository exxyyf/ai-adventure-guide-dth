## Labels

### L0

**`L0` — Correct Identification (точная идентификация)**

Модель правильно назвала конкретную достопримечательность.

- Критерии:

    * Совпадает уникальное имя

    * Нет двусмысленности

- Примеры:

    * “Notre-Dame de Paris”
  
    * “Colosseum in Rome”
 
    * “Eiffel Tower”


Это идеальный ответ

### L1

**`L1` — Near Correct / Specific but Wrong Name**

Объект определён почти правильно, но с ошибкой в конкретике.

- Критерии:

    * перепутан похожий объект

    * неверный официальный / разговорный вариант названия

    * ошибка в географии, но объект узнаваем

- Примеры:

    * “This is Chartres Cathedral” вместо Notre-Dame

    * “St. Peter’s Cathedral” вместо St. Peter’s Basilica

Модель «знает, что видит», но ошиблась


### L2

**`L2` — Correct Type, No Unique Identification**

Модель правильно поняла класс/тип объекта, но не смогла назвать конкретный.

- Критерии:

    * Тип / архитектурный стиль / функция определены верно

    * Уникальный объект не назван или назван слишком обобщённо

- Примеры:

    * “A Gothic cathedral in Europe”

    * “A medieval castle”

    * “A famous landmark, likely a cathedral”

Семантически верно, идентификационно — нет.

### L3

**`L3` — Incorrect / Hallucinated**

Модель неверно определила объект.

- Критерии:

    * Неверный тип

    * Фантазия / выдуманный объект

    * Полное несоответствие изображению

- Примеры:

    * “A modern skyscraper” (на фото готический собор)

    * “This is the Taj Mahal” (на фото европейская церковь)

Это ошибка модели


## How to annotate 

Ответь на вопросы по порядку:

Назван ли конкретный объект?

да → шаг 2

нет → если тип верен → L2, иначе L3

Название правильное?

да → L0

нет, но объект похож → L1

нет и тип неверен → L3

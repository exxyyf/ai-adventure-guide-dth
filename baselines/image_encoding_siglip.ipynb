{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install sentencepiece\n",
    "# %pip install protobuf\n",
    "# %pip install langchain_community\n",
    "# %pip install langchain\n",
    "# %pip install langchain_core\n",
    "# %pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import base64\n",
    "import torch\n",
    "from transformers import AutoModel, AutoProcessor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from tqdm import tqdm\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv('HF_TOKEN')\n",
    "MISTRAL_API_KEY = os.getenv('MISTRAL_API_KEY')\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_fpath = \"images\"\n",
    "if not os.path.exists(images_fpath):\n",
    "    os.mkdir(images_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SigLip embedding from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "VISION_MODEL = \"google/siglip-base-patch16-384\"\n",
    "\n",
    "vision_processor = AutoProcessor.from_pretrained(VISION_MODEL)\n",
    "vision_model = AutoModel.from_pretrained(VISION_MODEL).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_siglip(image_path):\n",
    "    \"\"\"Return L2-normalized SigLIP image embedding.\"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = vision_processor(images=img, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        emb = vision_model.get_image_features(**inputs)\n",
    "        emb = emb / emb.norm(dim=-1, keepdim=True)\n",
    "    return emb.cpu().numpy()[0].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_fpath = os.path.join(\n",
    "    images_fpath,\n",
    "    \"pamukkale.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_embedding = encode_image_siglip(pic_fpath)\n",
    "pic_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings from Wikivoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting into chunks: 100%|██████████| 24838/24838 [00:16<00:00, 1540.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 625336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 1. Load dataset\n",
    "# ---------------------------\n",
    "\n",
    "dataset = load_dataset(\"bigscience-data/roots_en_wikivoyage\", split=\"train\")\n",
    "texts = dataset[\"text\"]\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Split texts into chunks\n",
    "# ---------------------------\n",
    "\n",
    "chunk_size = 512\n",
    "chunk_overlap = 128\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "chunked_texts = []\n",
    "for text in tqdm(texts, desc=\"Splitting into chunks\"):\n",
    "    chunks = splitter.split_text(text)\n",
    "    chunked_texts.extend(chunks)\n",
    "\n",
    "print(\"Total chunks:\", len(chunked_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 4. SigLIP text embedding\n",
    "# ---------------------------\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_text_siglip(texts):\n",
    "    \"\"\"Return L2-normalized SigLIP text embedding.\"\"\"\n",
    "    inputs = vision_processor(text=texts, return_tensors=\"pt\", padding=True, truncation=True).to(DEVICE)\n",
    "    emb = vision_model.get_text_features(**inputs)\n",
    "    emb = emb / emb.norm(dim=-1, keepdim=True)\n",
    "    return emb.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding SigLIP embeddings: 100%|██████████| 19542/19542 [2:13:57<00:00,  2.43it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Compute embeddings\n",
    "siglip_embs = []\n",
    "batch_size = 32\n",
    "\n",
    "for i in tqdm(range(0, len(chunked_texts), batch_size), desc=\"Encoding SigLIP embeddings\"):\n",
    "    batch = chunked_texts[i:i+batch_size]\n",
    "    emb = encode_text_siglip(batch)\n",
    "    siglip_embs.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SigLIP embedding matrix shape: (625336, 768)\n",
      "FAISS SigLIP index built: 625336\n"
     ]
    }
   ],
   "source": [
    "siglip_embs = np.concatenate(siglip_embs, axis=0).astype(\"float32\")\n",
    "print(\"SigLIP embedding matrix shape:\", siglip_embs.shape)\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Build a separate FAISS index (cosine via inner product)\n",
    "# ---------------------------\n",
    "\n",
    "dim = siglip_embs.shape[1]\n",
    "\n",
    "index_siglip = faiss.IndexFlatIP(dim)\n",
    "index_siglip.add(siglip_embs)\n",
    "\n",
    "print(\"FAISS SigLIP index built:\", index_siglip.ntotal)\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Save everything\n",
    "# ---------------------------\n",
    "\n",
    "faiss.write_index(index_siglip, \"siglip.index\")\n",
    "np.save(\"siglip_embs.npy\", siglip_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"siglip_chunks.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunked_texts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 512\n",
    "chunk_overlap = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"embedding_dim\": dim,\n",
    "    \"chunk_size\": chunk_size,\n",
    "    \"chunk_overlap\": chunk_overlap,\n",
    "    \"total_chunks\": len(chunked_texts),\n",
    "    \"model\": \"google/google/siglip-base-patch16-384\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SigLIP index saved.\n"
     ]
    }
   ],
   "source": [
    "with open(\"siglip_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f)\n",
    "\n",
    "print(\"SigLIP index saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_siglip(image_path):\n",
    "    \"\"\"Return L2-normalized SigLIP image embedding.\"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = vision_processor(images=img, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        emb = vision_model.get_image_features(**inputs)\n",
    "        emb = emb / emb.norm(dim=-1, keepdim=True)\n",
    "    return emb.cpu().numpy()[0].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_search_siglip(image_path, k=5):\n",
    "    \"\"\"Search in SigLIP FAISS index by image similarity.\"\"\"\n",
    "    # load index + chunks\n",
    "    index_siglip = faiss.read_index(\"siglip.index\")\n",
    "    chunked_texts = pickle.load(open(\"siglip_chunks.pkl\", \"rb\"))\n",
    "\n",
    "    # embed image\n",
    "    image_emb = encode_image_siglip(image_path)\n",
    "\n",
    "    # similarity search\n",
    "    D, I = index_siglip.search(image_emb.reshape(1, -1), k)\n",
    "\n",
    "    results = []\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        results.append({\n",
    "            \"score\": float(score),\n",
    "            \"text\": chunked_texts[idx],\n",
    "            \"chunk_id\": int(idx)\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 636 ms, sys: 826 ms, total: 1.46 s\n",
      "Wall time: 3.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_search = image_search_siglip(pic_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.14834292232990265,\n",
       "  'text': 'Pamukkale is a hot spring with calcium-coated cliffs and pools in inland southeastern Aegean Turkey. Pamukkale, which has been used as a spa since the second century BC, literally means \"cotton castle\" in Turkish. The travertine features have their origins in the shifting of a fault in the valley of the Menderes river (between here and Denizli). As the fault shifted, very hot springs with a very high mineral content (notably chalk) arose at this location. Apart from the slightly radioactive minerals, the',\n",
       "  'chunk_id': 231993},\n",
       " {'score': 0.14748886227607727,\n",
       "  'text': '), so the travertines stay white as ever. This job is made tougher in winters when the water flowing down the chalky cascades will be freezing cold. Unfortunately in winter they not let water into the pools you can usually soak in in summer. Instead, just a little river is going downhill for warm your feet and a small waterfall to the side, but nothing to fully soak in. At the top of the travertines lies the ancient Roman city of Hierapolis. The ruins of the city sprawl over a large area, but sites are',\n",
       "  'chunk_id': 232001},\n",
       " {'score': 0.13994452357292175,\n",
       "  'text': 'pools go past your knees. Five minutes further up the white waterfalls of Pamukkale, you\\'ll find the hot springs of Hierapolis, where you can soak among sunken Roman columns (for a 20 Euro fee) submerged in an ancient pool. A series of hot springs extends across the landscape in the east of the country, where they are usually known as çermik, derived from the Armenian word for hot springs, chermug. Of particular note is the Balıklı Kaplıca (\"hot spring of the fish\") southeast of Sivas, where a local fish',\n",
       "  'chunk_id': 1762},\n",
       " {'score': 0.13958625495433807,\n",
       "  'text': \"The red spring is not even nearly as big as the calcium outcrop in Pamukkale, but worth a look. You might also want to try their mud baths. The entry to the site is free. 37.85580829.3856776 Kaklik Caves (about 30 minutes from Pamukkale). A small version of Pamukkale, but in an underground cave. You can walk down barefoot in the waterfalls from the village. The place is crowded when the tour-buses arrive. No shoes are allowed on the travertines. If you don't want to walk back to top, you can use the buses\",\n",
       "  'chunk_id': 232007},\n",
       " {'score': 0.13282039761543274,\n",
       "  'text': 'get-away from concrete sprawls of resorts 37.93972227.3486113 Ephesus — the best preserved of the ancient cities in Turkey, Ephesus was once the capital of Roman province of Asia Minor 37.92305629.1238894 Pamukkale — the \"cotton castle\", the white world of travertines 38.48833328.0402785 Sardis — the ruins of the capital of the Lydians, the inventors of \"money\", backed by the craggy Mt. Tmolos Aegean coast of Turkey is lined by a succession of modern cities with palm-lined avenues and liberal attitudes,',\n",
       "  'chunk_id': 74040}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это заработало"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

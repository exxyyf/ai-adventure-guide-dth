## Отчёт по созданию решения для загрузки картинки как инпута для RAG

Такие потенциальные решения вижу:

1. captioning, обращаемся к модели которая делает описание картинки текстом, прогоняем это через наш раг. раг остается без изменений почти, может понадобиться только особая доработка запроса когда с картинкой, например, добавить текст "расскажи об этом месте". решение - pixtral, доступна через апи. понятно что тут минусы это задержка при обращении, + еще одна АПИ ручка

2. моделью типа SigLip делаем отдельный векторстор эмбеддингов для текстов. при этом моделька делает эмбеддинг для картинок. потом если подается картинка, то мы делаем этой же моделью ее эмбеддинг, ищем в векторсторе нужные чанки, и нужные чанки отправляем в наш раг. таким образом, у нас два векторстора: от текстовой модели для текстовых запросов и от SigLip для запросов от картинок.

3. мультимодальный раг. на самом деле тут про то что одной этой мультимодальной моделью создаем эмбеддинги, и текстовые и картиночные вопросы подаем туда. потенциальные минусы в том, что качество эмбеддингов для текста ниже, чем если мы какую то прям хорошую модель возьмем под тексты

4. научить модельку (взять предобученную) классификатор, которая прям классифицирует картинку. лучше дообучать на данных с достопримечательностями. но как бы вот сомнительно, все не охватишь, учить сейчас не хочется. но можно попробовать предобученную. вижу сложности в том что много картинок разных и ошибки точно будут


Самые приоритетные для разработки - сценарии 1 и 2.

## Техническая проработка сценариев

Что удалось сделать:

### Сценарий 1

Получилось протестировать pixtral успешно, минимально модернизировать промт, модель выдает описание достопримечательности

### Сценарий 2

Получилось запустить SigLip, сделать эмбеддинг картинки

Получилось создать эмбеддинги для нашего базового датасета, а потом найти релевантные чанки по эмбеддингу картинки. Всё работает!
